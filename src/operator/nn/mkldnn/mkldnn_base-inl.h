/*******************************************************************************
* Copyright 2016-2017 Intel Corporation
*
* Licensed under the Apache License, Version 2.0 (the "License");
* you may not use this file except in compliance with the License.
* You may obtain a copy of the License at
*
*     http://www.apache.org/licenses/LICENSE-2.0
*
* Unless required by applicable law or agreed to in writing, software
* distributed under the License is distributed on an "AS IS" BASIS,
* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
* See the License for the specific language governing permissions and
* limitations under the License.
*
* \file mkldnn_base-inl.h
* \brief
* \author young.jin.kim@intel.com
*         ashok.emani@intel.com
*         deepthi.karkada@intel.com
*         louis.feng@intel.com
*         adam.d.straw@intel.com
*
*******************************************************************************/

#ifndef MXNET_OPERATOR_MKL_MKLDNN_BASE_INL_H_
#define MXNET_OPERATOR_MKL_MKLDNN_BASE_INL_H_

#if MXNET_USE_MKLDNN == 1
#include <string>
#include <vector>
#include <iterator>
#include "mkldnn.hpp"

namespace mxnet {
extern bool EnableMkldnnWarnGenerated();
// =====  CpuEngine =======================================
// cpu_engine singleton
class CpuEngine {
 public:
    static CpuEngine & Instance() {
        // I's thread-safe in C++11.
        static thread_local CpuEngine myInstance;
        return myInstance;
    }
    CpuEngine(CpuEngine const&) = delete;             // Copy construct
    CpuEngine(CpuEngine&&) = delete;                  // Move construct
    CpuEngine& operator=(CpuEngine const&) = delete;  // Copy assign
    CpuEngine& operator=(CpuEngine &&) = delete;      // Move assign

    mkldnn::engine & get_engine() { return _cpu_engine; }
 protected:
    CpuEngine() : _cpu_engine(mkldnn::engine::cpu, 0) {}
    ~CpuEngine() {}
 private:
    mkldnn::engine _cpu_engine;
};

// type enumerator
template<typename T>
struct data_type_enum {};

template<>
struct data_type_enum<float> {
    enum { type = mkldnn::memory::data_type::f32 };
};

template<>
struct data_type_enum<int32_t> {
    enum { type = mkldnn::memory::data_type::s32 };
};

template<>
struct data_type_enum<int16_t> {
    enum { type = mkldnn::memory::data_type::s16 };
};

template<>
struct data_type_enum<int8_t> {
    enum { type = mkldnn::memory::data_type::s8 };
};

template<>
struct data_type_enum<uint8_t> {
    enum { type = mkldnn::memory::data_type::u8 };
};

static inline mkldnn::memory::data_type get_mkldnn_type(int dtype) {
  switch(dtype) {
    case mshadow::kFloat32:
      return mkldnn::memory::data_type::f32;
    default:
      return mkldnn::memory::data_type::data_undef;
  }
}

inline static mkldnn::memory::desc GetMemDesc(const NDArray &arr, int ndim) {
  mkldnn::memory::dims dims(ndim);
  for (size_t i = 0; i < dims.size(); i++)
    dims[i] = arr.shape()[i];
  return mkldnn::memory::desc{dims, get_mkldnn_type(arr.dtype()),
    mkldnn::memory::format::any};
}

inline static mkldnn::memory::desc GetMemDesc(const NDArray &arr) {
  return GetMemDesc(arr, arr.shape().ndim());
}

inline static mkldnn::memory::desc GetWeightDesc(const NDArray &arr,
    int num_groups) {
  if (num_groups == 1) {
    return GetMemDesc(arr);
  }
  else {
    CHECK_EQ(arr.shape().ndim(), 4U);
    mkldnn::memory::dims tz = mkldnn::memory::dims{num_groups,
      (int) arr.shape()[0] / num_groups, (int) arr.shape()[1],
      (int) arr.shape()[2], (int) arr.shape()[3]};
    return mkldnn::memory::desc{tz, get_mkldnn_type(arr.dtype()),
      mkldnn::memory::format::any};
  }
}

typedef std::shared_ptr<mkldnn::memory> mkldnn_mem_ptr;
typedef std::shared_ptr<const mkldnn::memory> mkldnn_mem_const_ptr;

class MKLDNNStream {
  std::vector<mkldnn::primitive> net;
  // Here we hold all memory related to the operators in the stream.
  std::vector<mkldnn_mem_const_ptr> mem_holder;
public:
  static MKLDNNStream &Instance() {
    static thread_local MKLDNNStream stream;
    return stream;
  }

  void RegisterPrim(const mkldnn::primitive &prim) {
    net.push_back(prim);
  }

  void RegisterMem(mkldnn_mem_const_ptr mem) {
    mem_holder.push_back(mem);
  }

  void Submit() {
    mkldnn::stream(mkldnn::stream::kind::eager).submit(net).wait();
    net.clear();
    mem_holder.clear();
  }
};

inline static mkldnn_mem_ptr CreateMKLDNNMem(const mkldnn::memory::primitive_desc &desc) {
  // TODO allocate memory more efficiently.
  std::shared_ptr<mkldnn::memory> ret(new mkldnn::memory(desc));
  MKLDNNStream::Instance().RegisterMem(ret);
  return ret;
}

enum OutDataOp {
  Noop,
  CopyBack,
  AddBack,
};

typedef std::pair<OutDataOp, mkldnn_mem_ptr> mkldnn_output_t;

static inline mkldnn_output_t CreateMKLDNNMem(const NDArray &arr,
    const mkldnn::memory::primitive_desc &desc, OpReqType req) {
  if (kAddTo == req)
    return mkldnn_output_t(OutDataOp::AddBack, CreateMKLDNNMem(desc));
  else {
    mkldnn_mem_ptr mem = const_cast<NDArray &>(arr).CreateMKLDNNData(desc);
    if (mem == nullptr)
      return mkldnn_output_t(OutDataOp::CopyBack, CreateMKLDNNMem(desc));
    else
      return mkldnn_output_t(OutDataOp::Noop, mem);
  }
}

namespace op {
void Sum(const mkldnn::memory &arr1, const mkldnn::memory &arr2,
    const mkldnn::memory &out);
}

static inline void CommitOutput(const NDArray &arr, const mkldnn_output_t &res) {
  if (res.first == CopyBack)
    const_cast<NDArray &>(arr).CopyFrom(*res.second);
  else if (res.first == AddBack) {
    // TODO I might need to reorder.
    mkldnn_mem_const_ptr mem = arr.GetMKLDNNData(res.second->get_primitive_desc());
    op::Sum(*res.second, *mem, *mem);
  }
}

inline static mkldnn_mem_const_ptr GetWeights(const NDArray &arr,
    const mkldnn::memory::primitive_desc &target_pd, int num_groups) {
  mkldnn_mem_const_ptr mem;
  mkldnn::memory::data_type type = get_mkldnn_type(arr.dtype());
  auto engine = CpuEngine::Instance().get_engine();
  if (arr.shape().ndim() == 2) {
    mkldnn::memory::dims tz = mkldnn::memory::dims{(int) arr.shape()[0],
      (int) arr.shape()[1]};
    mkldnn::memory::desc md = mkldnn::memory::desc{tz, type, mkldnn::memory::format::oi};
    mkldnn::memory::primitive_desc pd = mkldnn::memory::primitive_desc{md, engine};
    mem = arr.GetMKLDNNData(pd);
  }
  else if (arr.shape().ndim() == 4 && num_groups == 1) {
    mkldnn::memory::dims tz = mkldnn::memory::dims{(int) arr.shape()[0],
      (int) arr.shape()[1], (int) arr.shape()[2], (int) arr.shape()[3]};
    mkldnn::memory::desc md = mkldnn::memory::desc{tz, type, mkldnn::memory::format::oihw};
    mkldnn::memory::primitive_desc pd = mkldnn::memory::primitive_desc{md, engine};
    mem = arr.GetMKLDNNData(pd);
  }
  else if (arr.shape().ndim() == 4) {
    mkldnn::memory::dims tz = mkldnn::memory::dims{num_groups, (int) arr.shape()[0] / num_groups,
      (int) arr.shape()[1], (int) arr.shape()[2], (int) arr.shape()[3]};
    mkldnn::memory::desc md = mkldnn::memory::desc{tz, type, mkldnn::memory::format::goihw};
    mkldnn::memory::primitive_desc pd = mkldnn::memory::primitive_desc{md, engine};
    mem = arr.GetMKLDNNData(pd);
  }
  else {
    LOG(FATAL) << "The weight array has an unsupported number of dimensions";
    return nullptr;
  }
  if (mem->get_primitive_desc() == target_pd)
    return mem;

  std::shared_ptr<mkldnn::memory> ret = CreateMKLDNNMem(target_pd);
  MKLDNNStream::Instance().RegisterPrim(mkldnn::reorder(*mem, *ret));
  return ret;
}

inline static mkldnn_mem_const_ptr GetWeights(const NDArray &arr,
    const mkldnn::engine &engine, int num_groups = 1) {
  mkldnn::memory::data_type type = get_mkldnn_type(arr.dtype());
  if (arr.shape().ndim() == 2) {
    mkldnn::memory::dims tz = mkldnn::memory::dims{(int) arr.shape()[0],
      (int) arr.shape()[1]};
    mkldnn::memory::desc md = mkldnn::memory::desc{tz, type, mkldnn::memory::format::oi};
    mkldnn::memory::primitive_desc pd = mkldnn::memory::primitive_desc{md, engine};
    return arr.GetMKLDNNData(pd);
  }
  else if (arr.shape().ndim() == 4 && num_groups == 1) {
    mkldnn::memory::dims tz = mkldnn::memory::dims{(int) arr.shape()[0],
      (int) arr.shape()[1], (int) arr.shape()[2], (int) arr.shape()[3]};
    mkldnn::memory::desc md = mkldnn::memory::desc{tz, type, mkldnn::memory::format::oihw};
    mkldnn::memory::primitive_desc pd = mkldnn::memory::primitive_desc{md, engine};
    return arr.GetMKLDNNData(pd);
  }
  else if (arr.shape().ndim() == 4) {
    mkldnn::memory::dims tz = mkldnn::memory::dims{num_groups, (int) arr.shape()[0] / num_groups,
      (int) arr.shape()[1], (int) arr.shape()[2], (int) arr.shape()[3]};
    mkldnn::memory::desc md = mkldnn::memory::desc{tz, type, mkldnn::memory::format::goihw};
    mkldnn::memory::primitive_desc pd = mkldnn::memory::primitive_desc{md, engine};
    return arr.GetMKLDNNData(pd);
  }
  else {
    LOG(FATAL) << "The weight array has an unsupported number of dimensions";
    return nullptr;
  }
}

}  // namespace mxnet
#endif
#endif  // MXNET_OPERATOR_MKL_MKLDNN_BASE_INL_H_
